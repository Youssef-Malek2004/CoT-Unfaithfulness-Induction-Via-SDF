{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-22T14:48:17.700007Z",
     "start_time": "2025-12-22T14:47:44.307057Z"
    }
   },
   "source": [
    "# If you're on Mac, you generally do NOT want bitsandbytes.\n",
    "# !pip -q install accelerate datasets transformers\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# ---- device ----\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---- tokenizer ----\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ---- model ----\n",
    "# MPS usually works best if you load in float16 and move to mps explicitly.\n",
    "# (If you hit instability, change torch.float16 -> torch.float32.)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if device == \"mps\" else torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"sdpa\",  # fine on recent PyTorch; if issues, remove this line\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n",
    "\n",
    "# ---- data ----\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "train_dataset = dataset[\"train\"].filter(lambda x: len(x[\"text\"].strip()) > 0).select(range(5000))\n",
    "eval_dataset  = dataset[\"validation\"].filter(lambda x: len(x[\"text\"].strip()) > 0).select(range(500))\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=False,\n",
    "    )\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "tokenized_eval  = eval_dataset.map(tokenize_function, batched=True, remove_columns=eval_dataset.column_names)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# ---- training ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deepseek-finetuned-mac\",\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "\n",
    "    # IMPORTANT for Mac:\n",
    "    fp16=False,               # don't use Trainer's fp16 on MPS\n",
    "    bf16=False,               # set True only if you KNOW your Mac + torch supports it well\n",
    "\n",
    "    optim=\"adamw_torch\",      # mac-safe optimizer\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    "\n",
    "    dataloader_num_workers=0, # mac often happier with 0\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b25f78e4acad44758bbba45dbfaaa9db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 16:48:02.966 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_02-2638859746‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:02.983 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_02-4206292096‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:02.989 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_02-2429357442‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.054 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-716933158‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.059 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-3545956999‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.067 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-3944280061‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.073 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-3599654972‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.076 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-300556139‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.082 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-2292766573‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.085 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-2411741244‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.090 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-1126382449‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.096 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-1708521928‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.099 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-111096245‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.101 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-947713343‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.104 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-3934702740‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.110 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-2336302508‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.113 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-1529313992‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.116 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-2399596619‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n",
      "2025-12-22 16:48:03.120 python[99068:1389696] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-99068-2025-12-22_16_48_03-640803098‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[2], line 100\u001B[0m\n\u001B[1;32m     92\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     93\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     94\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     97\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator,\n\u001B[1;32m     98\u001B[0m )\n\u001B[0;32m--> 100\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/transformers/trainer.py:2325\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   2324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   2326\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   2327\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[1;32m   2328\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[1;32m   2329\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[1;32m   2330\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/transformers/trainer.py:2715\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2714\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m grad_norm_context():\n\u001B[0;32m-> 2715\u001B[0m         _grad_norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\n\u001B[1;32m   2716\u001B[0m             model\u001B[38;5;241m.\u001B[39mparameters(),\n\u001B[1;32m   2717\u001B[0m             args\u001B[38;5;241m.\u001B[39mmax_grad_norm,\n\u001B[1;32m   2718\u001B[0m         )\n\u001B[1;32m   2720\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2721\u001B[0m     is_accelerate_available()\n\u001B[1;32m   2722\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED\n\u001B[1;32m   2723\u001B[0m ):\n",
      "File \u001B[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/accelerate/accelerator.py:3009\u001B[0m, in \u001B[0;36mAccelerator.clip_grad_norm_\u001B[0;34m(self, parameters, max_norm, norm_type)\u001B[0m\n\u001B[1;32m   3008\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_gradients()\n\u001B[0;32m-> 3009\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(parameters, max_norm, norm_type\u001B[38;5;241m=\u001B[39mnorm_type)\n",
      "File \u001B[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:82\u001B[0m, in \u001B[0;36mclip_grad_norm_\u001B[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001B[0m\n\u001B[1;32m     81\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m g \u001B[38;5;129;01min\u001B[39;00m grads:\n\u001B[0;32m---> 82\u001B[0m             g\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mmul_(clip_coef_clamped_device)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_norm\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3598\u001B[0m, in \u001B[0;36mInteractiveShell.run_code\u001B[0;34m(self, code_obj, result, async_)\u001B[0m\n\u001B[1;32m   3596\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m   3597\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3598\u001B[0m         result\u001B[38;5;241m.\u001B[39merror_in_exec \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mexc_info()[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3599\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshowtraceback(running_compiled_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   3600\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e14391b457bd2403"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
